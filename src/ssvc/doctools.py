#!/usr/bin/env python
#  Copyright (c) 2023 Carnegie Mellon University and Contributors.
#  - see Contributors.md for a full list of Contributors
#  - see ContributionInstructions.md for information on how you can Contribute to this project
#  Stakeholder Specific Vulnerability Categorization (SSVC) is
#  licensed under a MIT (SEI)-style license, please see LICENSE.md distributed
#  with this Software or contact permission@sei.cmu.edu for full terms.
#  Created, in part, with funding and support from the United States Government
#  (see Acknowledgments file). This program may include and/or can make use of
#  certain third party source code, object code, documentation and other files
#  (“Third Party Software”). See LICENSE.md for more details.
#  Carnegie Mellon®, CERT® and CERT Coordination Center® are registered in the
#  U.S. Patent and Trademark Office by Carnegie Mellon University
"""
Provides tools to assist with generating documentation for SSVC decision points.
"""
import logging
import os

from ssvc.decision_points.base import REGISTERED_DECISION_POINTS, SsvcDecisionPoint
from ssvc.dp_groups.ssvc.collections import SSVCv1, SSVCv2, SSVCv2_1  # noqa

logger = logging.getLogger(__name__)


def _filename_friendly(name: str) -> str:
    """
    Given a string, return a version that is friendly for use in a filename.

    Args:
        name (str): The string to make friendly for use in a filename.

    Returns:
        str: A version of the string that is friendly for use in a filename.
    """
    return name.lower().replace(" ", "_").replace(".", "_")


MD_TABLE_ROW_TEMPLATE = "| {value.name} | {value.description} |"

# indent by 4 spaces to make it a code block
MD_INCLUDE_TEMPLATE = """<!-- This content is autogenerated by doctools.py. Do not Edit. -->
!!! note "{dp.name} v{dp.version}"

    === "Text" 
    
        {table}
        
    === "JSON"
    
        ```json
        {{% include "{json_file}" %}}
        ```
"""


def to_markdown_table(dp: SsvcDecisionPoint) -> str:
    rows = []
    # prepend the header
    rows.append(f"{dp.description}")
    rows.append("")
    indent = " " * 8
    rows.append(f"{indent}| Value | Definition |")
    rows.append(f"{indent}|:-----|:-----------|")

    # add a row for each value
    for value in dp.values:
        rows.append(indent + MD_TABLE_ROW_TEMPLATE.format(value=value))

    return "\n".join(rows)


# create a runtime context that ensures that dir exists
class EnsureDirExists:
    def __init__(self, dir):
        self.dir = dir

    def __enter__(self):
        os.makedirs(self.dir, exist_ok=True)

    def __exit__(self, exc_type, exc_val, exc_tb):
        pass


def remove_if_exists(file):
    try:
        os.remove(file)
    except FileNotFoundError:
        logger.debug(f"File {file} does not exist, nothing to remove")
        pass


def dump_decision_point(jsondir, outdir, dp, overwrite):
    # - generate markdown table
    # make dp.name safe for use in a filename
    basename = _filename_friendly(dp.name) + f"_{_filename_friendly(dp.version)}"
    # - generate json example
    json_file = dump_json(basename, dp, jsondir, overwrite)

    # - generate markdown tabbed element file
    dump_markdown(basename, dp, json_file, outdir, overwrite)


def dump_markdown(basename, dp, json_file, outdir, overwrite):
    include_file = f"{outdir}/{basename}.md"

    relative_json_file = os.path.relpath(json_file, outdir)

    if overwrite:
        remove_if_exists(include_file)
    with EnsureDirExists(outdir):
        try:
            with open(include_file, "x") as f:
                formatted_template = MD_INCLUDE_TEMPLATE.format(
                    dp=dp,
                    json_file=relative_json_file,
                    table=(to_markdown_table(dp)),
                )
                f.write(formatted_template)
        except FileExistsError:
            logger.warning(
                f"File {include_file} already exists, use --overwrite to replace"
            )

    # update the symlink
    # because we don't want to have to edit each markdown file every time something changes
    symlink = f"{outdir}/{_filename_friendly(dp.name)}.md"
    remove_if_exists(symlink)
    relative_md_file = os.path.relpath(include_file, outdir)
    os.symlink(relative_md_file, symlink)


def dump_json(basename, dp, jsondir, overwrite):
    json_file = f"{jsondir}/{basename}.json"
    if overwrite:
        remove_if_exists(json_file)
    with EnsureDirExists(jsondir):
        dp._comment = "This file is autogenerated by doctools.py. Do not Edit."
        try:
            with open(json_file, "x") as f:
                f.write(dp.to_json(indent=2))
        except FileExistsError:
            logger.warning(
                f"File {json_file} already exists, use --overwrite to replace"
            )
    return json_file


def main():
    # we are going to generate three files for each decision point:
    # - a markdown table that can be used in the decision point documentation
    # - a json example that can be used in the decision point documentation
    # - a markdown file that builds an mkdocs tabbed element to switch between the markdown description and the json
    #   example using markdown-include plugin of mkdocs

    # parse command line args
    import argparse

    parser = argparse.ArgumentParser(
        description="Generate decision point documentation"
    )
    parser.add_argument(
        "--overwrite",
        action="store_true",
        help="overwrite existing files",
        default=False,
    )

    parser.add_argument("--outdir", help="output directory", default="./tmp/md_out")
    parser.add_argument(
        "--jsondir", help="json output directory", default="./tmp/json_out"
    )
    args = parser.parse_args()

    overwrite = args.overwrite
    outdir = args.outdir
    jsondir = args.jsondir

    # for each decision point:
    for dp in REGISTERED_DECISION_POINTS:
        dump_decision_point(jsondir, outdir, dp, overwrite)


if __name__ == "__main__":
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)
    if not logger.hasHandlers():
        hdlr = logging.StreamHandler()
        logger.addHandler(hdlr)

    _root = os.path.abspath(os.path.dirname(__file__))

    main()
