
# References
<!-- Once these are all converted to definitions of hyperlinks to be used in the document, then the heading should be removed as this file won't actually print anything -->


[Benetis et al. 2019]: https://www.first.org/standards/frameworks/csirts/csirt_services_framework_v2.1
"Vilius Benetis, Olivier Caleff, Cristine Hoepers, Angela Horneman,
    Allen Householder, Klaus-Peter Kossakowski, Art Manion, Amanda
    Mullens, Samuel Perl, Daniel Roethlisberger, Sigitas Rokas, Mary
    Rossell, Robin M. Ruefle, D’esir’ee Sacher, Krassimir T. Tzvetanov,
    and Mark Zajicek. Computer security incident response team (CSIRT)
    services framework. Technical Report ver. 2.1, FIRST, Cary, NC, USA,
    July 2019."

2.  Spring, Jonathan. M., and Phyllis Illari. Review of human
    decision-making during computer security incident analysis. 2019.
    arXiv:1903.10080.

3.  “CVSS provides a way to capture the principal characteristics of a
    vulnerability … reflecting its severity … to help organizations
    properly assess and prioritize their vulnerability management
    processes.” See “Common Vulnerability Scoring System SIG”
    ([https://www.first.org/cvss](https://www.first.org/cvss/)).

4.  The base score is defined as “the intrinsic characteristics of a
    vulnerability that are constant over time and across user
    environments.” FIRST. Common Vulnerability Scoring System version
    3.1: Specification Document*.*

5.  Suggested for use by federal civilian departments and agencies via
    NIST guidance (e.g., SP 800-115, p. 7-4 and SP 800-40r3 pg. 4) and
    the DHS directive on Critical Vulnerability Mitigation
    (<https://cyber.dhs.gov/bod/15-01/>).

6.  Via PCI DSS, see:
    <https://www.pcisecuritystandards.org/documents/ASV_Program_Guide_v3.0.pdf>

7.  Chase, Penny and Stevey Christey Coley. *Rubric for Applying CVSS to
    Medical Devices*. MITRE and the FDA. 2019.

8.  Vilches, Víctor Mayoral, Endika Gil-Uriarte, Irati Zamalloa Ugarte,
    Gorka Olalde Mendia, Rodrigo Izquierdo Pisón, Laura Alzola
    Kirschgens, Asier Bilbao Calvo, Alejandro Hernández Cordero, Lucas
    Apa, and César Cerrudo. *Towards an open standard for assessing the
    severity of robot security vulnerabilities, the Robot Vulnerability
    Scoring System (RVSS)*. arXiv:1807.10357 (2018).

9.  Santiago Figueroa-Lorenzo, Javier Añorga, and Saioa Arrizabalaga. A
    survey of IIoT protocols: A measure of vulnerability risk analysis
    based on cvss. ACM Comput. Surv., 53(2), April 2020.

10. These include, but are not limited to :Red Hat
    (<https://access.redhat.com/security/updates/classification>),
    Microsoft
    (<https://www.microsoft.com/en-us/msrc/security-update-severity-rating-system>),
    and Cisco
    (<https://tools.cisco.com/security/center/resources/security_vulnerability_policy.html#asr>).

11. Spring, Jonathan M., Eric Hatleback, Allen Householder, Art Manion,
    Deana Shick. *Towards Improving CVSS*. Carnegie Mellon University,
    Software Engineering Institute, Pittsburgh, PA. 2018.
    <u>https://resources.sei.cmu.edu/library/asset-view.cfm?assetid=538368</u>.

12. For example: Farris KA, Shah A, Cybenko G, Ganesan R, Jajodia S.
    VULCON: A System for Vulnerability Prioritization, Mitigation, and
    Management. ACM Transactions on Privacy and Security (TOPS). 2018
    Jun 12; 21(4):16.

13. Allodi, Luca and Fabio Massacci. A Preliminary Analysis of
    Vulnerability Scores for Attacks in Wild: The EKITS and SYM
    Datasets. BADGERS’12, Oct 5, 2012, Raleigh, North Carolina, USA.

14. Allodi L.; Cremonini M.; Massacci F.; & Shim W. The Effect of
    Security Education and Expertise on Security Assessments: The Case
    of Software Vulnerabilities. In WEIS 2018

15. Garfinkel, Simson, and Heather Richter Lipford. Usable security:
    History, themes, and challenges. Morgan & Claypool Publishers, 2014.

16. Pendleton, Marcus, Richard Garcia-Lebron, Jin-Hee Cho, and Shouhuai
    Xu. A survey on systems security metrics. ACM Comput. Surv., 49(4),
    December 2016.

17. Stefan Laube and Rainer Böhme. Strategic aspects of cyber risk
    information sharing. ACM Comput. Surv., 50(5), November 2017.

18. Jonathan M Spring, Tyler Moore, and David Pym. 2017. Practicing a
    Science of Security: A philosophy of science perspective. In New
    Security Paradigms Workshop. Santa Cruz, CA, USA.

19. Simon, Herbert A. The sciences of the artificial. 3<sup>rd</sup> ed.
    MIT press, 1996.

20. Common Vulnerability Scoring System v3.1: Specification Document.
    2019. See Section 7.5.
    https://www.first.org/cvss/v3.1/specification-document

21. Russell, Stuart J. & Norvig, Peter. *Artificial Intelligence: A
    Modern Approach,* *3rd Edition*. Prentice Hall. 2010. ISBN
    9780136042594.

22. Howard, Ronald A and James E Matheson, eds. Readings on the
    Principles and Applications of Decision Analysis. Strategic
    Decisions Group. 1983. Pg viii.

23. Burch H.; Manion A.; & Ito Y. *Vulnerability Response Decision
    Assistance (VRDA).* Software Engineering Institute, Carnegie Mellon
    University. June 2007.
    <u>https://resources.sei.cmu.edu/library/asset-view.cfm?assetid=51036</u>

24. Allen D. Householder; Garret Wassermann; Art Manion; & Chris King.
    The CERT® Guide to Coordinated Vulnerability Disclosure. Section
    6.10,
    <u>https://vuls.cert.org/confluence/display/CVD/6.10+Troubleshooting+Coordinated+Vulnerability+Disclosure+Table</u>

25. Allodi L.; Cremonini M.; Massacci F.; & Shim W. *The Effect of
    Security Education and Expertise on Security Assessments: The Case
    of Software Vulnerabilities*. In WEIS 2018, Figure 1. The more
    accurate half of professionals estimated CVSS scores in ranges such
    as \[+2,0\] (i.e., between overestimating by 2 to being correct),
    \[+2,-2\], and \[0,-2\].

26. Spring J.; Kern S.; & Summers A. *Global adversarial capability
    modeling*. APWG Symposium on Electronic Crime Research (eCrime). May
    2015. IEEE.

27. Spring J.M. & Illari P. Building general knowledge of mechanisms in
    information security. *Philosophy & Technology*. **32**, 627–659.
    2018.

28. Jay Jacobs; Sasha Romanosky; Idris Adjerid; & Wade Baker. *Improving
    Vulnerability Remediation Through Better Exploit Prediction*. WEIS.
    Boston, MA. June 2019.

29. Appliers use this feature only as a suggested constraint on the
    values for *mission impact*.

30. Hutchins, E.M.; Cloppert, M.J.; & Amin, R.M. “Intelligence-driven
    computer network defense informed by analysis of adversary campaigns
    and intrusion kill chains.” *Leading Issues in Information Warfare &
    Security Research*. 2011: 1(1):80.

31. <u>https://zerodium.com/program.html</u>

32. Centers for Disease Control and Prevention. “How is well-being
    defined?” <https://www.cdc.gov/hrqol/wellbeing.htm#three>.
    Health-Related Quality of Life (HRQOL). August 2019.

33. By “system operator” we mean those who are professionally
    responsible for the proper operation of the cyber-physical system,
    as the term is used in the safety analysis literature.

34. These categories are based on hazard categories for aircraft
    software. See DO-187C (Software Considerations in Airborne Systems
    and Equipment Certification) and Section 3.3.2 of the *[FAA System
    Safety
    Handbook](https://www.faa.gov/regulations_policies/handbooks_manuals/aviation/risk_management/ss_handbook/media/Chap3_1200.pdf),*
    Dec 2000
    (<https://www.faa.gov/regulations_policies/handbooks_manuals/aviation/risk_management/ss_handbook/media/Chap3_1200.pdf>).

35. For information about identification of mission essential functions,
    see *Federal Continuity Directive 2: Federal Executive Branch
    Mission Essential Functions and Candidate Primary Mission Essential
    Functions Identification and Submission Process* from June 2017
    (<https://www.fema.gov/media-library-data/1499702987348-c8eb5e5746bfc5a7a3cb954039df7fc2/FCD-2June132017.pdf>).

36. Brett Tucker. OCTAVE® FORTE and FAIR Connect Cyber Risk
    Practitioners with the Boardroom. June 2018.
    <u>https://insights.sei.cmu.edu/insider-threat/2018/06/octave-forte-and-fair-connect-cyber-risk-practitioners-with-the-boardroom.html</u>

37. Captera. IT Asset Management Software. May 24, 2020.
    <https://www.capterra.com/it-asset-management-software/>

38. Michelle Jump and Art Manion. 2019. Framing Software Component
    Transparency: Establishing a Common Software Bill of Material
    (SBOM). Technical Report. National Telecommunications and
    Information Administration, Washington, DC.

39. <u>https://en.wikipedia.org/wiki/Content\_management\_system</u>

40. Fleiss, Joseph L., and Jacob Cohen. "The equivalence of weighted
    kappa and the intraclass correlation coefficient as measures of
    reliability." *Educational and psychological measurement* 33, no. 3
    (1973): 613-619.

41. Allen D. Householder; Garret Wassermann; Art Manion; & Chris King.
    The CERT® Guide to Coordinated Vulnerability Disclosure. Section 3.
    <https://vuls.cert.org/confluence/display/CVD/3.+Roles+in+CVD>

42. *Ibid.* 15

43. Muhammad Akbar. A Critical First Look at Stakeholder Specific
    Vulnerability Categorization (SSVC). Mar 6, 2020.
    <https://blog.secursive.com/posts/critical-look-stakeholder-specific-vulnerability-categorization-ssvc/>

44. Falotico, Rosa, and Piero Quatto. "Fleiss’ kappa statistic without
    paradoxes." *Quality & Quantity* 49, no. 2 (2015): 463-470.

45. This is not the case with CVSSv3; expert assessment of scores varies
    widely. See Figure 1 in *The Effect of Security Education and
    Expertise on Security Assessments: The Case of Software
    Vulnerabilities* by Luca Allodi, Marco Cremonini, Fabio Massacci,
    and Woohyun Shim, published in WEIS in 2018.

46. We have not discussed a convenient compressed expression of a set of
    SSVC decision points. Initialisms similar to a CVSS vector are used
    here; Exploitation (E), Technical impact (T), Utility (U), Safety
    Impact (S), Exposure (X), and Mission impact (M). S:M is minor, S:J
    is major; M:F is MEF failure, M:M is mission failure. However, since
    we created Utility in response to the System Value metric’s
    shortcomings, the pilot results do not include systematic consensus
    on Utility values.

47. Caralli, Richard; Stevens, James; Young, Lisa; & Wilson, William.
    *Introducing OCTAVE Allegro: Improving the Information Security Risk
    Assessment Process*. CMU/SEI-2007-TR-012. Software Engineering
    Institute. Carnegie Mellon University. 2007.
    <u>http://resources.sei.cmu.edu/library/asset-view.cfm?AssetID=8419</u>
